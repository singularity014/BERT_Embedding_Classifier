# Transformer_BERT_Experiment
# BERT EMbedding based model vs Non-BERT Embedding model comparison

1) This repo gives a step by step guide of using BERT Style tokenizer and how it can be used for tasks like sentiment analysis with models like CNN, LSTM    etc. BERT has a unique way of tokenizing, and we could leverage similar tokenization technique to feed tokenized data to our traditional models.
2) After the tokenization process is done we will see how to use BERT Embedding layer to obtain features.
3) We will then build a 1-D CNN model for sentiment classification task. (But it can be any other model as well)
4) To comapare the results obtained by using the model built in the git repo
   - https://github.com/singularity014/BERT_Tokenizer_for_classification Vs the model buil in this repo.
5) We can see how positional contextual embedding methods can improve our results.
